{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, 1]\n",
    "y_train = train.iloc[:, 2:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/surajiiitm/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove unnecessary words\n",
    "text = x_train[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_to_words(comments):\n",
    "    comments = str(comments)\n",
    "    letters_only = re.sub('[^A-Za-z]', \" \", comments)\n",
    "    letters = letters_only.lower()\n",
    "\n",
    "    words = letters.split()\n",
    "\n",
    "    # removing stopword using nltk\n",
    "    # remove stop words from words\n",
    "    vector_words = [word for word in words if not word in stopword]\n",
    "    return (\" \".join(vector_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = comment_to_words(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review 1000 of 159571\n",
      "review 2000 of 159571\n",
      "review 3000 of 159571\n",
      "review 4000 of 159571\n",
      "review 5000 of 159571\n",
      "review 6000 of 159571\n",
      "review 7000 of 159571\n",
      "review 8000 of 159571\n",
      "review 9000 of 159571\n",
      "review 10000 of 159571\n",
      "review 11000 of 159571\n",
      "review 12000 of 159571\n",
      "review 13000 of 159571\n",
      "review 14000 of 159571\n",
      "review 15000 of 159571\n",
      "review 16000 of 159571\n",
      "review 17000 of 159571\n",
      "review 18000 of 159571\n",
      "review 19000 of 159571\n",
      "review 20000 of 159571\n",
      "review 21000 of 159571\n",
      "review 22000 of 159571\n",
      "review 23000 of 159571\n",
      "review 24000 of 159571\n",
      "review 25000 of 159571\n",
      "review 26000 of 159571\n",
      "review 27000 of 159571\n",
      "review 28000 of 159571\n",
      "review 29000 of 159571\n",
      "review 30000 of 159571\n",
      "review 31000 of 159571\n",
      "review 32000 of 159571\n",
      "review 33000 of 159571\n",
      "review 34000 of 159571\n",
      "review 35000 of 159571\n",
      "review 36000 of 159571\n",
      "review 37000 of 159571\n",
      "review 38000 of 159571\n",
      "review 39000 of 159571\n",
      "review 40000 of 159571\n",
      "review 41000 of 159571\n",
      "review 42000 of 159571\n",
      "review 43000 of 159571\n",
      "review 44000 of 159571\n",
      "review 45000 of 159571\n",
      "review 46000 of 159571\n",
      "review 47000 of 159571\n",
      "review 48000 of 159571\n",
      "review 49000 of 159571\n",
      "review 50000 of 159571\n",
      "review 51000 of 159571\n",
      "review 52000 of 159571\n",
      "review 53000 of 159571\n",
      "review 54000 of 159571\n",
      "review 55000 of 159571\n",
      "review 56000 of 159571\n",
      "review 57000 of 159571\n",
      "review 58000 of 159571\n",
      "review 59000 of 159571\n",
      "review 60000 of 159571\n",
      "review 61000 of 159571\n",
      "review 62000 of 159571\n",
      "review 63000 of 159571\n",
      "review 64000 of 159571\n",
      "review 65000 of 159571\n",
      "review 66000 of 159571\n",
      "review 67000 of 159571\n",
      "review 68000 of 159571\n",
      "review 69000 of 159571\n",
      "review 70000 of 159571\n",
      "review 71000 of 159571\n",
      "review 72000 of 159571\n",
      "review 73000 of 159571\n",
      "review 74000 of 159571\n",
      "review 75000 of 159571\n",
      "review 76000 of 159571\n",
      "review 77000 of 159571\n",
      "review 78000 of 159571\n",
      "review 79000 of 159571\n",
      "review 80000 of 159571\n",
      "review 81000 of 159571\n",
      "review 82000 of 159571\n",
      "review 83000 of 159571\n",
      "review 84000 of 159571\n",
      "review 85000 of 159571\n",
      "review 86000 of 159571\n",
      "review 87000 of 159571\n",
      "review 88000 of 159571\n",
      "review 89000 of 159571\n",
      "review 90000 of 159571\n",
      "review 91000 of 159571\n",
      "review 92000 of 159571\n",
      "review 93000 of 159571\n",
      "review 94000 of 159571\n",
      "review 95000 of 159571\n",
      "review 96000 of 159571\n",
      "review 97000 of 159571\n",
      "review 98000 of 159571\n",
      "review 99000 of 159571\n",
      "review 100000 of 159571\n",
      "review 101000 of 159571\n",
      "review 102000 of 159571\n",
      "review 103000 of 159571\n",
      "review 104000 of 159571\n",
      "review 105000 of 159571\n",
      "review 106000 of 159571\n",
      "review 107000 of 159571\n",
      "review 108000 of 159571\n",
      "review 109000 of 159571\n",
      "review 110000 of 159571\n",
      "review 111000 of 159571\n",
      "review 112000 of 159571\n",
      "review 113000 of 159571\n",
      "review 114000 of 159571\n",
      "review 115000 of 159571\n",
      "review 116000 of 159571\n",
      "review 117000 of 159571\n",
      "review 118000 of 159571\n",
      "review 119000 of 159571\n",
      "review 120000 of 159571\n",
      "review 121000 of 159571\n",
      "review 122000 of 159571\n",
      "review 123000 of 159571\n",
      "review 124000 of 159571\n",
      "review 125000 of 159571\n",
      "review 126000 of 159571\n",
      "review 127000 of 159571\n",
      "review 128000 of 159571\n",
      "review 129000 of 159571\n",
      "review 130000 of 159571\n",
      "review 131000 of 159571\n",
      "review 132000 of 159571\n",
      "review 133000 of 159571\n",
      "review 134000 of 159571\n",
      "review 135000 of 159571\n",
      "review 136000 of 159571\n",
      "review 137000 of 159571\n",
      "review 138000 of 159571\n",
      "review 139000 of 159571\n",
      "review 140000 of 159571\n",
      "review 141000 of 159571\n",
      "review 142000 of 159571\n",
      "review 143000 of 159571\n",
      "review 144000 of 159571\n",
      "review 145000 of 159571\n",
      "review 146000 of 159571\n",
      "review 147000 of 159571\n",
      "review 148000 of 159571\n",
      "review 149000 of 159571\n",
      "review 150000 of 159571\n",
      "review 151000 of 159571\n",
      "review 152000 of 159571\n",
      "review 153000 of 159571\n",
      "review 154000 of 159571\n",
      "review 155000 of 159571\n",
      "review 156000 of 159571\n",
      "review 157000 of 159571\n",
      "review 158000 of 159571\n",
      "review 159000 of 159571\n"
     ]
    }
   ],
   "source": [
    "num_comment = len(x_train)\n",
    "processed_comment = []\n",
    "for i in range(0, num_comment):\n",
    "    if((i+1)%1000 == 0 ):\n",
    "        print(\"review %d of %d\" %((i+1), num_comment))\n",
    "    processed_comment.append(comment_to_words(x_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=None,\n",
    "                             stop_words=None,\n",
    "                             max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(processed_comment)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.sum(train_data_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(720, input_shape=(5000,), activation='relu'))\n",
    "classifier.add(Dense(36, activation='relu'))\n",
    "classifier.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "159571/159571 [==============================] - 118s 742us/step - loss: 0.0762 - acc: 0.9780\n",
      "Epoch 2/5\n",
      "159571/159571 [==============================] - 118s 740us/step - loss: 0.0489 - acc: 0.9837\n",
      "Epoch 3/5\n",
      "159571/159571 [==============================] - 118s 741us/step - loss: 0.0385 - acc: 0.9872\n",
      "Epoch 4/5\n",
      "159571/159571 [==============================] - 120s 755us/step - loss: 0.0292 - acc: 0.9907\n",
      "Epoch 5/5\n",
      "159571/159571 [==============================] - 120s 750us/step - loss: 0.0227 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6344b1668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_data_features, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "# predicting the test set result\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment 1000 of 153164\n",
      "comment 2000 of 153164\n",
      "comment 3000 of 153164\n",
      "comment 4000 of 153164\n",
      "comment 5000 of 153164\n",
      "comment 6000 of 153164\n",
      "comment 7000 of 153164\n",
      "comment 8000 of 153164\n",
      "comment 9000 of 153164\n",
      "comment 10000 of 153164\n",
      "comment 11000 of 153164\n",
      "comment 12000 of 153164\n",
      "comment 13000 of 153164\n",
      "comment 14000 of 153164\n",
      "comment 15000 of 153164\n",
      "comment 16000 of 153164\n",
      "comment 17000 of 153164\n",
      "comment 18000 of 153164\n",
      "comment 19000 of 153164\n",
      "comment 20000 of 153164\n",
      "comment 21000 of 153164\n",
      "comment 22000 of 153164\n",
      "comment 23000 of 153164\n",
      "comment 24000 of 153164\n",
      "comment 25000 of 153164\n",
      "comment 26000 of 153164\n",
      "comment 27000 of 153164\n",
      "comment 28000 of 153164\n",
      "comment 29000 of 153164\n",
      "comment 30000 of 153164\n",
      "comment 31000 of 153164\n",
      "comment 32000 of 153164\n",
      "comment 33000 of 153164\n",
      "comment 34000 of 153164\n",
      "comment 35000 of 153164\n",
      "comment 36000 of 153164\n",
      "comment 37000 of 153164\n",
      "comment 38000 of 153164\n",
      "comment 39000 of 153164\n",
      "comment 40000 of 153164\n",
      "comment 41000 of 153164\n",
      "comment 42000 of 153164\n",
      "comment 43000 of 153164\n",
      "comment 44000 of 153164\n",
      "comment 45000 of 153164\n",
      "comment 46000 of 153164\n",
      "comment 47000 of 153164\n",
      "comment 48000 of 153164\n",
      "comment 49000 of 153164\n",
      "comment 50000 of 153164\n",
      "comment 51000 of 153164\n",
      "comment 52000 of 153164\n",
      "comment 53000 of 153164\n",
      "comment 54000 of 153164\n",
      "comment 55000 of 153164\n",
      "comment 56000 of 153164\n",
      "comment 57000 of 153164\n",
      "comment 58000 of 153164\n",
      "comment 59000 of 153164\n",
      "comment 60000 of 153164\n",
      "comment 61000 of 153164\n",
      "comment 62000 of 153164\n",
      "comment 63000 of 153164\n",
      "comment 64000 of 153164\n",
      "comment 65000 of 153164\n",
      "comment 66000 of 153164\n",
      "comment 67000 of 153164\n",
      "comment 68000 of 153164\n",
      "comment 69000 of 153164\n",
      "comment 70000 of 153164\n",
      "comment 71000 of 153164\n",
      "comment 72000 of 153164\n",
      "comment 73000 of 153164\n",
      "comment 74000 of 153164\n",
      "comment 75000 of 153164\n",
      "comment 76000 of 153164\n",
      "comment 77000 of 153164\n",
      "comment 78000 of 153164\n",
      "comment 79000 of 153164\n",
      "comment 80000 of 153164\n",
      "comment 81000 of 153164\n",
      "comment 82000 of 153164\n",
      "comment 83000 of 153164\n",
      "comment 84000 of 153164\n",
      "comment 85000 of 153164\n",
      "comment 86000 of 153164\n",
      "comment 87000 of 153164\n",
      "comment 88000 of 153164\n",
      "comment 89000 of 153164\n",
      "comment 90000 of 153164\n",
      "comment 91000 of 153164\n",
      "comment 92000 of 153164\n",
      "comment 93000 of 153164\n",
      "comment 94000 of 153164\n",
      "comment 95000 of 153164\n",
      "comment 96000 of 153164\n",
      "comment 97000 of 153164\n",
      "comment 98000 of 153164\n",
      "comment 99000 of 153164\n",
      "comment 100000 of 153164\n",
      "comment 101000 of 153164\n",
      "comment 102000 of 153164\n",
      "comment 103000 of 153164\n",
      "comment 104000 of 153164\n",
      "comment 105000 of 153164\n",
      "comment 106000 of 153164\n",
      "comment 107000 of 153164\n",
      "comment 108000 of 153164\n",
      "comment 109000 of 153164\n",
      "comment 110000 of 153164\n",
      "comment 111000 of 153164\n",
      "comment 112000 of 153164\n",
      "comment 113000 of 153164\n",
      "comment 114000 of 153164\n",
      "comment 115000 of 153164\n",
      "comment 116000 of 153164\n",
      "comment 117000 of 153164\n",
      "comment 118000 of 153164\n",
      "comment 119000 of 153164\n",
      "comment 120000 of 153164\n",
      "comment 121000 of 153164\n",
      "comment 122000 of 153164\n",
      "comment 123000 of 153164\n",
      "comment 124000 of 153164\n",
      "comment 125000 of 153164\n",
      "comment 126000 of 153164\n",
      "comment 127000 of 153164\n",
      "comment 128000 of 153164\n",
      "comment 129000 of 153164\n",
      "comment 130000 of 153164\n",
      "comment 131000 of 153164\n",
      "comment 132000 of 153164\n",
      "comment 133000 of 153164\n",
      "comment 134000 of 153164\n",
      "comment 135000 of 153164\n",
      "comment 136000 of 153164\n",
      "comment 137000 of 153164\n",
      "comment 138000 of 153164\n",
      "comment 139000 of 153164\n",
      "comment 140000 of 153164\n",
      "comment 141000 of 153164\n",
      "comment 142000 of 153164\n",
      "comment 143000 of 153164\n",
      "comment 144000 of 153164\n",
      "comment 145000 of 153164\n",
      "comment 146000 of 153164\n",
      "comment 147000 of 153164\n",
      "comment 148000 of 153164\n",
      "comment 149000 of 153164\n",
      "comment 150000 of 153164\n",
      "comment 151000 of 153164\n",
      "comment 152000 of 153164\n",
      "comment 153000 of 153164\n"
     ]
    }
   ],
   "source": [
    "num_reviews = len(test[\"comment_text\"])\n",
    "clean_test_comments = []\n",
    "\n",
    "for i in range(0, num_reviews):\n",
    "    if (i+1)%1000 == 0:\n",
    "        print(\"comment %d of %d\" %((i+1), num_reviews))\n",
    "    clean_test_comments.append(comment_to_words(test[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(clean_test_comments)\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "result1 = classifier.predict_proba(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999995 , 0.44507396, 0.99986875, 0.0370819 , 0.9795308 ,\n",
       "       0.14327948], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each category probability model prediction\n",
    "output = np.column_stack([test[\"id\"], result1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00001cee341fdb12', 0.9999995231628418, 0.4450739622116089,\n",
       "       0.9998687505722046, 0.03708190470933914, 0.9795308113098145,\n",
       "       0.14327947795391083], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.rename(index=str, columns={0:\"id\", 1:\"toxic\", 2:\"severe_toxic\", 3:\"obscene\", 4:\"threat\", 5:\"insult\", 6:\"identity_hate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv(\"toxic_comment.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_reviews):\n",
    "    if output.iloc[i][\"id\"] == \"0114509409588767\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00001cee341fdb12'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.iloc[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
